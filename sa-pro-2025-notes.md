# Systems Manager Patch Manager

This tool automates patching of your EC2 and on-premises servers.

**What does it handle?**

 ‚úÖ Automatically scans for missing patches
 ‚úÖ Defines patch rules (baselines)
 ‚úÖ Groups servers for patching (Patch Groups)
 ‚úÖ Applies patches in a controlled, environment-aware way

 Key Concepts *Systems Manager Patch Manager*

 1Ô∏è‚É£ *Patch Baseline*
 * This defines which patches should be applied.
Example:
Baseline for Dev: all non-critical + critical patches
Baseline for Prod: only critical patches, with a 7-day wait
üí° Think of it as your ‚Äúapproved patch rulebook‚Äù per environment.
2Ô∏è‚É£ Patch Group
* Logical grouping of EC2 instances based on tags.
* **MUST use the tag key: Patch Group** (this is an AWS rule).
Example:
    Dev instances ‚Üí Patch Group = Dev-Patch
    Prod instances ‚Üí Patch Group = Prod-Patch
üí° Patch Groups connect specific servers to specific baselines.
3Ô∏è‚É£ Tagging
* You must tag EC2 instances properly:
 ‚úÖ By environment
 ‚úÖ By OS type (if needed)
 Example:
Environment: Dev, Patch Group: Dev-Patch
Environment: Prod, Patch Group: Prod-Patch
üí° Without the right tags, Patch Manager can‚Äôt target the right servers.
4Ô∏è‚É£ Patch Compliance
After patching, you can verify what was patched, what failed, and what‚Äôs missing.

# VPC & Networking (Peering, TGW, Direct Connect)
1Ô∏è‚É£ Trap: VPC Peering is NOT transitive.
 ‚û°Ô∏è Even if A ‚ÜîÔ∏è B and B ‚ÜîÔ∏è C, A üö´ cannot talk to C.

2Ô∏è‚É£ Trap: Direct Connect does NOT allow VPC-to-VPC traffic.
 ‚û°Ô∏è It connects on-premises to AWS‚ÄîNOT VPC-to-VPC. Use Transit Gateway + 

 Direct Connect Gateway for multi-VPC routing.
#  IAM & Security (Cross-Account Access, Policies)
1Ô∏è‚É£ Trap: Resource-based policies allow cross-account access WITHOUT switching roles.

    ‚û°Ô∏è Identity-based policies need AssumeRole.

2Ô∏è‚É£ Trap: Trust Policy‚Äôs Principal must point to the external account/user ARN‚ÄîNOT to your own account or role name.

# CloudFront & Encryption
1Ô∏è‚É£ Trap: Field-Level Encryption is needed when encrypting specific sensitive fields (e.g., credit card numbers), not just HTTPS.
2Ô∏è‚É£ Trap: Adding headers (User-Agent, Host) to CloudFront cache key can reduce cache hit ratio, NOT improve it.

# Migration Strategies (6 R‚Äôs)
1Ô∏è‚É£ Trap: If you're migrating NOW with no code changes, it‚Äôs always Rehost‚Äîeven if you plan to refactor later

2Ô∏è‚É£ Trap: Replatform = minor tweaks now (e.g., moving DB to RDS)‚ÄîNOT a full rewrite (that's Refactor).

üß† **Blue/Green works** best when you can duplicate everything and switch over cleanly.
‚ùå It‚Äôs not ideal when apps need live state coordination, feature flags, or have tight upgrade paths (like COTS apps).

# Security Groups vs NACLs
1Ô∏è‚É£ Trap: Security Groups are stateful (return traffic auto-allowed); NACLs are stateless (must allow return traffic explicitly).

2Ô∏è‚É£ Trap: NACLs evaluate rules in order (lowest # first). First match WINS. SGs evaluate all rules together.

# Direct Connect & VPN
1Ô∏è‚É£ Trap: VPN is over the internet (IPSec encrypted), while Direct Connect is a dedicated private connection.

2Ô∏è‚É£ Trap: Public VIF (Virtual Interface) on Direct Connect is for public AWS services (e.g., S3), NOT for private VPC access. For VPC access, you need a Private VIF.

# S3 Access & Encryption
1Ô∏è‚É£ Trap: Bucket policies (resource-based) can grant cross-account access directly. IAM user policies alone can‚Äôt do this unless combined with AssumeRole.

2Ô∏è‚É£ Trap: S3 encryption:
SSE-S3 = AWS manages keys
SSE-KMS = You manage keys via KMS
 ‚û°Ô∏è **SSE-KMS requires extra permission to use the key (kms:Decrypt, etc.).**
 # IPSEC VPN and VPC 

 1Ô∏è‚É£ IPSec tunnels are built for ‚Äúon-prem to AWS,‚Äù not AWS VPC to AWS VPC.
 2Ô∏è‚É£ Instead of IPSec, AWS gives you:
  * VPC Peering
  * Transit Gateway (TGW)

‚û°Ô∏è These are AWS-native solutions that use the AWS backbone network‚Äîthey don‚Äôt need IPSec tunnels.

| Scenario                                              | Solution(s)                                  | Notes                                  |
|------------------------------------------------------|----------------------------------------------|----------------------------------------|
| Connect on-prem <--> AWS VPC securely (encrypted)    | ‚úÖ Site-to-Site VPN (IPSec tunnel)           | AWS Native Solution                    |
| Connect VPC <--> VPC (same region or inter-region)   | ‚úÖ VPC Peering OR Transit Gateway            | NO IPSec tunnel involved               |
| Connect multiple VPCs + scale easily                 | ‚úÖ Transit Gateway (TGW)                     |                                        |
| Connect multi-region + on-prem in one go             | ‚úÖ Direct Connect + Direct Connect Gateway   |                                        |

üö® KEY PHRASE TO MEMORIZE:
 üëâ ‚ÄúAWS does NOT provide native IPSec VPN tunnels between two VPCs; use VPC Peering or Transit Gateway instead.‚Äù


 | AWS Config                                                                 | AWS Systems Manager (SSM)                                           |
|----------------------------------------------------------------------------|---------------------------------------------------------------------|
| üõ°Ô∏è **Think:** Continuous Compliance & Auditing                             | üîß **Think:** Managing, Operating & Patching your infrastructure    |
| Tracks & records the state of your resources (configuration history).       | Lets you manage servers, install patches, run commands, automate ops tasks. |
| Continuously checks if resources meet compliance rules.                     | Example: ‚ÄúPatch my EC2 Linux machines. Run a script across all servers.‚Äù |
| Example: ‚ÄúAre my S3 buckets public? Is my IAM policy too open?‚Äù            |                                                                     |
| You ask: ‚ÄúIs my AWS resource configured correctly & compliant?‚Äù             | You ask: ‚ÄúHow do I manage and operate my servers and services?‚Äù     |
| ‚úÖ **Best for:** Auditing, compliance, security monitoring.                 | ‚úÖ **Best for:** Automation, maintenance, operational tasks.         |

üö® The BIG TRAP to Remember for the Exam:
üëâ **If the question is about:**
‚ùì Compliance, auditing, continuously checking policies or configs:
 ‚û°Ô∏è ‚úÖ **AWS Config is the answer.**


‚ùì Running commands, patching servers, automating operational tasks:
 ‚û°Ô∏è ‚úÖ **WS Systems Manager (SSM) is the answer.**


üí° Easy phrase:
üîë ‚ÄúConfig = Compliance. SSM = SysAdmin tasks.‚Äù
‚úÖ When question says:
‚ÄúUser keeps working in their account + no need to switch roles‚Äù ‚ûî ‚úÖ Resource-based policy.

# üöÄ  How to Improve Cache Hit Ratio:

| Technique                                 | Why It Helps                                                                                   |
|--------------------------------------------|-----------------------------------------------------------------------------------------------|
| Cache-Control max-age (longer TTL)         | The longer CloudFront can cache content, the fewer times it goes back to the origin.           |
| Minimize unnecessary headers/query strings | CloudFront caches per unique request. Extra headers/query strings can cause cache misses.      |
| Compress objects (gzip/brotli)             | Reduces size = faster = more cache-friendly.                                                   |
| Use Origin Shield                          | Adds another caching layer closer to your origin, improving cache hit ratio for multi-region requests. |
| Versioned URLs (e.g., /v1/logo.png)        | Lets you cache forever (long TTL) and force refresh only when you change the file (by changing the URL). |

# AWS Security services usecase

| Use Case                                      | AWS Service            | Included/Status     |
|-----------------------------------------------|------------------------|---------------------|
| Infra-layer DDoS protection (SYN, UDP)        | AWS Shield Advanced    | ‚úÖ                  |
| Track and enforce resource config compliance  | AWS Config             | ‚úÖ                  |
| App-level threats (SQLi, XSS, bots)           | AWS WAF                |                     |
| Org-wide firewall/DDoS policy enforcement     | AWS Firewall Manager   |                     |
| Patch, automate EC2 ops                       | AWS Systems Manager    |                     |

üß± WAF Core Building Blocks

| Component                    | What It Does                                                                                           |
|------------------------------|--------------------------------------------------------------------------------------------------------|
| Web ACL (Access Control List) | The main WAF rule group you attach to resources (like ALB, API Gateway, CloudFront)                    |
| Rules                        | Logic like "block all SQLi", "allow only US IPs", "rate limit per IP"                                  |
| Rule Groups                  | Reusable sets of rules, like AWS Managed Rule Groups (pre-built protections)                           |


| Scenario                          | Federation Type           | STS Call                  |
|------------------------------------|---------------------------|---------------------------|
| Enterprise/On-Prem Users (AD, ADFS)| ‚úÖ SAML Federation         | AssumeRoleWithSAML        |
| Mobile/Web App Users (Google, FB)  | ‚ùå Web Identity Federation | AssumeRoleWithWebIdentity |
| OAuth 2.0 Access                   | ‚ùå Not supported for console login | ‚Äî                |

‚ÄúSAML for corporate users, Web Identity for app users.‚Äù
üîë ‚ÄúSTS + AssumeRoleWithSAML = enterprise login via SSO‚Äù
Forward Proxy = the ONLY option that gives URL-level outbound control from EC2 instances

üß† Trigger Phrase for VPN CloudHub in Exam:
‚Äúmultiple remote sites‚Äù + ‚ÄúVPN‚Äù + ‚Äúhub-and-spoke‚Äù + ‚Äúcost-effective‚Äù
"Want to block direct S3 access and force CloudFront access? ‚Üí Use OAI

 security groups and network ACLs. Security groups control inbound and outbound traffic for your instances, and network ACLs control inbound and outbound traffic for your subnets

AWS Storage Gateway iSCSI security against replay or spoofing attacks?
‚úÖ Enable CHAP authentication for initiator and target

# EBS

| Data Pattern                      | Volume Type         |
|------------------------------------|--------------------|
| Random access (DB)                 | gp3/gp2 or io1     |
| Sequential access (logs, streaming)| st1                |
| Infrequent, archived, cold         | sc1                |

# Migration tool

| Use Case                | Migration Tool | Storage Type                                         |
|-------------------------|---------------|------------------------------------------------------|
| Full server (VMs, whole OS) | SMS           | Based on general disk type                           |
| Database only           | DMS           | Match volume type to access pattern (gp2, io1, st1, sc1) |


## When to Use Signed Cookies vs Signed URLs

| Use Case                                 | Use Signed URLs | Use Signed Cookies |
|------------------------------------------|:--------------:|:-----------------:|
| User needs access to one file            |      ‚úÖ Yes     |      ‚ùå Not ideal  |
| User needs access to many files          |      ‚ùå No      |      ‚úÖ Yes        |
| You don‚Äôt want to change URLs            |      ‚ùå No      |      ‚úÖ Yes        |
| Protecting video libraries, images, docs |      ‚ùå No      |      ‚úÖ Yes        |


---

## Mobile App Authentication Best Practices

- Mobile apps that use Google/Facebook login = **Web Identity Federation + STS + temporary creds**
- ‚ùå **Never** hardcode access keys into mobile apps.
- ‚úÖ **Always** let users log in with their identity provider and get temporary access to AWS.


| Federation Type         | Use Case                                                                 | STS API Used                      | Credential Type                           | Best For                                           | Security Risk                           |
|-------------------------|--------------------------------------------------------------------------|-----------------------------------|-------------------------------------------|----------------------------------------------------|------------------------------------------|
| Web Identity Federation | Mobile/web apps using Google, Facebook, or OIDC login                   | AssumeRoleWithWebIdentity         | Temporary credentials (via STS)           | Apps where users log in with social accounts       | Low (uses short-lived tokens)           |
| SAML Federation         | Enterprise users with corporate credentials (e.g., ADFS, AD)            | AssumeRoleWithSAML                | Temporary credentials (via STS)           | Enterprise SSO and centralized user management     | Low (tokens expire)                     |
| Cognito                 | User sign-up/sign-in with AWS-hosted identity/user pools                | Cognito handles internally with STS | Temporary credentials (via STS)           | Consumer apps with user directory and auth mgmt    | Low (tokens + user pool auth)           |
| IAM Users               | Static, long-lived AWS identities (not federated)                       | Not applicable                    | Long-term access keys (manually rotated)  | Scripts, CLI use, admin users (bad for apps)       | High (long-term keys can be leaked)     |

# Ldap and Identity broker

‚úÖ What is an Identity Broker?
An identity broker is like a translator and gatekeeper between:
üßë Your corporate identity system (LDAP, AD, etc.)

üîÑ It does 3 main jobs:
Authenticate the user using LDAP


Map the authenticated user to an IAM Role in AWS


Request temporary AWS credentials from STS using AssumeRole


‚òÅÔ∏è AWS Security Token Service (STS)

Your identity broker sits between LDAP and AWS


It verifies the user credentials against LDAP


If successful, it calls AWS STS (AssumeRole) and gives back temporary AWS credentials


The web app calls the broker and uses the credentials returned to access AWS

**User ‚Üí Web App ‚Üí Identity Broker ‚Üí LDAP + STS ‚Üí Temporary AWS creds**
**Mental model: LDAP ‚Üí Broker ‚Üí STS ‚Üí AWS creds**

| Step | What Happens                                               |
|------|-----------------------------------------------------------|
| 1Ô∏è‚É£   | User logs into web app with LDAP credentials              |
| 2Ô∏è‚É£   | Web app or broker verifies credentials against LDAP       |
| 3Ô∏è‚É£   | If valid, it calls AWS STS: AssumeRole                   |
| 4Ô∏è‚É£   | Gets temporary credentials for that IAM role              |
| 5Ô∏è‚É£   | App uses those creds to access S3, DynamoDB, etc.         |

Memory Hook
**‚ÄúLDAP can‚Äôt talk to IAM directly‚ÄîSTS is the translator, and the identity broker is the bouncer.‚Äù**

| Component      | Purpose                                  |
|----------------|------------------------------------------|
| LDAP           | Corporate user authentication            |
| Identity Broker| Maps LDAP user to IAM role and calls STS |
| STS            | Issues temporary AWS credentials         |
| IAM Role       | Controls what the user can access in AWS |

‚úÖ Benefits of Identity Broker
üîê No need for long-term IAM users or access keys
üîÅ Temporary credentials that auto-expire
üõ°Ô∏è Strong access control using IAM roles
üîÑ Works with any identity provider (LDAP, SAML, OIDC)

| Concept                | Example                                                        |
|------------------------|----------------------------------------------------------------|
| You control the key    | You create it yourself, AWS never stores it                    |
| You send the key       | Every time you upload/download, you must include the key       |
| AWS encrypts for you   | But only temporarily, then forgets the key                     |
| Headers matter         | You must send 3 headers with API/SDK/CLI calls                 |


"You can‚Äôt change your VPC‚Äôs original block, but you CAN expand it with 4 more CIDRs."
 CIDR expansion ‚â† VPC peering.

 # RDS 

 **Why CNAME, Not IP Address?**
RDS gives your DB instance a CNAME DNS endpoint like:

 CopyEdit
mydb.abcdefghij.us-east-1.rds.amazonaws.com


This CNAME always points to the current primary


AWS flips it behind the scenes during failover

That‚Äôs why apps should **always connect using the RDS endpoint** and not the underlying IP‚Äîbecause IPs change on failover, but the **CNAME stays the same.*

Multi-AZ = standby is on standby. If primary dies, AWS promotes standby and flips the CNAME‚Äîfast, smooth, automatic.

# üß† RDS High Availability & Scaling Cheat Sheet

| Feature               | Multi-AZ Deployment                              | Read Replica                                  | Global Database                              |
|----------------------|--------------------------------------------------|-----------------------------------------------|----------------------------------------------|
| üîÑ Purpose            | High availability (failover support)             | Read scalability                              | Cross-region disaster recovery & reads       |
| üë®‚Äçüíª Usage Pattern     | Production databases needing HA                  | Reporting, analytics, read-heavy workloads     | Global apps with low-latency read access     |
| üîÉ Replication Type   | Synchronous (real-time replication)              | Asynchronous                                  | Asynchronous                                  |
| üìö Used For Reads     | ‚ùå No (standby cannot serve traffic)              | ‚úÖ Yes (you can connect to read replicas)       | ‚úÖ Yes (cross-region reads supported)         |
| üîß Writes Allowed     | ‚úÖ Primary only                                   | ‚ùå No (read-only copies)                       | ‚ùå No (except primary region)                 |
| ‚õëÔ∏è Failover Support   | ‚úÖ Automatic failover to standby                  | ‚ùå Not automatic (must manually promote)       | ‚úÖ Manual or semi-automatic regional failover |
| üåê Region Support     | Single region                                    | Single region (or cross-region)               | ‚úÖ Multi-region                               |
| üìé Endpoint Type      | One endpoint (CNAME, auto-flips on failover)     | One per replica                               | One per region                               |
| ‚ö†Ô∏è Common Mistakes    | Confused with read scaling                       | Not HA ‚Äì no automatic failover                | Not suitable for fast write replication      |
| üí∏ Cost Implication   | Charged for both primary & standby               | Charged per replica                           | Higher cost due to replication & latency     |
| üß™ Best Use Case      | Tier-1 production apps needing 99.99% uptime     | Apps with lots of read traffic                | Multi-region, global-critical workloads       |

**‚úÖ Key Takeaways:**

- **Multi-AZ = HA**, **not** read scaling.
- **Read Replica = Scaling**, **not** HA.
- **Global DB = Worldwide scale**, **disaster resilience**.

> ‚ö° Always use the **RDS endpoint (CNAME)** when connecting. AWS auto-flips it during failover in Multi-AZ.

## Key FSx Variants and Their Use Cases

| FSx Variant               | Description                                                                                   | Ideal Use Cases                                                      |
|---------------------------|----------------------------------------------------------------------------------------------|---------------------------------------------------------------------|
| FSx for Windows File Server | Fully managed Windows file system with support for SMB protocol and Active Directory integration. | Windows-based applications, home directories, lift-and-shift migrations. |
| FSx for Lustre            | High-performance file system optimized for fast processing of workloads.                     | Machine learning, high-performance computing (HPC), and big data analytics. |
| FSx for NetApp ONTAP      | Provides NetApp's ONTAP file system capabilities with multi-protocol access.                 | Enterprises needing NetApp features like SnapMirror and FlexClone.   |
| FSx for OpenZFS           | Offers OpenZFS file system with features like snapshots and data cloning.                    | Applications requiring ZFS features, data protection, and efficient data cloning. |

---

## M-A-C-I-E = ‚ÄúMonitoring And Classification In Everything‚Äù

**Amazon Macie:**
- Detects PII
- Flags risky data storage
- Classifies data in S3 buckets

---

## CloudFront + HTTPS (Viewer Layer)

‚úÖ **Use Viewer Protocol Policy:**
- Redirect HTTP to HTTPS (best UX)
- HTTPS Only (most secure)

‚úÖ **Use CloudFront‚Äôs default SSL cert** (for `*.cloudfront.net`)

‚ùå **Do NOT use self-signed certs** at ELB or S3 with CloudFront

‚ùå **ELB doesn‚Äôt have a default cert**; needs ACM or imported cert

> Use CloudFront + Viewer Protocol Policy to enforce HTTPS and boost SEO üîê

---

## GuardDuty and Trusted IPs

- GuardDuty only trusts IPs, not EC2 instance IDs.
- To suppress findings from specific EC2s, give them Elastic IPs and add those IPs to the Trusted IP list.


## Section Migration and Modernization


# Correct DNS Rule Summary for Route 53

**MEMORIZE THIS TABLE**

| AWS Resource Type           | Route 53 Record Type      | Alias Allowed? | Notes                            |
|----------------------------|---------------------------|:-------------:|----------------------------------|
| EC2 instance               | A record (non-alias)      |      ‚ùå        | Use IP address directly          |
| Elastic Load Balancer (ELB)| A record (Alias)          |      ‚úÖ        | Must use Alias A record          |
| CloudFront                 | A record (Alias)          |      ‚úÖ        | Required for apex domains        |
| S3 Static Website          | A record (Alias)          |      ‚úÖ        | Needs static hosting enabled     |
| RDS Endpoint               | CNAME only                |      ‚ùå        | AWS manages RDS CNAME            |

Route 53 + ELB = Alias A Record (Not regular A Record)
When routing to ELB, use Alias A record so AWS handles DNS resolution dynamically.
example.com ‚Üí Alias A ‚Üí ELB DNS (xyz.us-east-1.elb.amazonaws.com)


This allows DNS to automatically follow fail overs and changes.

# Application Migration Service (MGN) vs Database Migration Service (DMS)

| Service | Purpose                                      |
|---------|----------------------------------------------|
| **MGN** | Lift-and-shift VMs/servers (like EC2 migrations) |
| **DMS** | Migrate databases (like MySQL to RDS)           

**Memorization Trick for Route 53:**
```
"ELB, S3, CloudFront ‚Äì Alias A is the Front.
 RDS ‚Äì Use CNAME, No Alias zone."
 ```

 MGN ‚Üí for mission-critical VMs
Keeps them online, automates cutover, minimal downtime

‚úî Snowball ‚Üí for bulk migration of non-critical VMs
40TB over 12Mbps = >310 days (would miss the 3-month deadline)


Snowball completes the data move in ~1 week

‚úî VM Import/Export ‚Üí to make them run as EC2
Converts your VMs to AMI format, boots them in AWS

# AWS Migration Decision Table

Use this table to quickly determine the recommended AWS migration tool or service based on your scenario:

| **Condition**                               | **Use**           |
|---------------------------------------------|-------------------|
| Limited internet + large data (TBs)         | Snowball          |
| Live VMs / low downtime                     | MGN               |
| Simple lift-and-shift + pre-exported VMs    | VM Import/Export  |
| Replatform/refactor                         | Only if explicitly asked |
| Large budget + need low latency             | Direct Connect    |

## Migration Strategy Cheat Sheet for AWS Pro

### Use AWS MGN when:
- VMs need low downtime
- Continuous replication required
- Lift-and-shift approach

### Use Snowball when:
- TBs or PBs of data
- Network is a bottleneck
- Cost-effective offline transfer needed

### Use VM Import/Export when:
- VMs already exported
- No real-time cutover needed

### Avoid Direct Connect when:
- Budget is tight
- No ongoing hybrid needs

# CORE CONCEPT: When to Use AWS Application Migration Service (MGN)

| Requirement                        | Why MGN Fits                                                                                 |
|-------------------------------------|---------------------------------------------------------------------------------------------|
| ‚úÖ Import on-prem VMs               | MGN supports lift-and-shift from VMware, Hyper-V, and physical servers                      |
| ‚úÖ Sync changes until cutover       | MGN uses continuous block-level replication via lightweight agents                          |
| ‚úÖ Terabytes of root + data volume  | It replicates all attached volumes automatically                                            |
| ‚úÖ Minimal downtime                 | After testing, you cutover with near-zero downtime                                          |
| ‚úÖ Minimal ops overhead             | Fully automated, no need for custom scripts like in VM Import/Export                        |

# REMEMBER FOR EXAM: MGN vs VM Import/Export

| Feature                | MGN (AWS Application Migration Service) | VM Import/Export         |
|------------------------|:--------------------------------------:|:------------------------:|
| Continuous sync        | ‚úÖ Yes                                 | ‚ùå No                    |
| Minimal downtime       | ‚úÖ Yes                                 | ‚ùå High downtime (re-import entire image) |
| Multi-volume support   | ‚úÖ All attached volumes                | ‚ùå Manual snapshots needed|
| Automation             | ‚úÖ Highly automated                    | ‚ùå Manual scripts or CLI  |
| Best for               | Lift-and-shift, rehosting              | One-time imports         |
| Replication agent needed? | ‚úÖ Yes                              | ‚ùå No                    |

# AWS Application Migration Service (MGN)

## Use Case:
- Lift-and-shift migration of on-prem VMs (VMware, Hyper-V, physical)
- Minimal downtime required
- Sync changes until production cutover

## Benefits:
- Block-level continuous replication
- Automates launch of EC2 from replicated images
- Supports data + root volumes
- Test + Cutover workflows built-in
- Zero manual re-imports or scripting needed

## Key Differences:
- MGN > VM Import/Export when downtime is unacceptable
- MGN supports re-platform/refactor later

## Important:
- Install replication agent
- Plan launch templates per instance
- Cutover stops replication and finalizes migration

**üõ† Key Workflow with MGN**
Install agent on source servers (Windows/Linux)
MGN does block-level replication
Perform Test launch from AWS
Validate functionality
Do a Cutover launch
Decommission old systems üéØ

# AWS Storage Gateway ‚Äì Tape Gateway

## Purpose:
Modernize on-premises **tape backups** by moving to **Amazon S3 + Glacier** using virtual tapes.

## How It Works:
1. Existing backup software (e.g., Veeam, NetBackup) writes to **virtual tape** (iSCSI)
2. Tape data is stored in **Amazon S3**
3. Archived tapes are moved to **Virtual Tape Shelf (VTS)** in **Amazon Glacier**

## Benefits:
- Minimal changes to legacy backup processes
- High durability (99.999999999%) via Glacier
- Pay-as-you-go archival storage
- Avoids physical tape management

## Notes:
- **VTS** = Glacier storage location for virtual tapes
- Can't retrieve archived tapes immediately ‚Äì must restore first
- **Don't use File Gateway or Volume Gateway** for tape backups
Use AWS Schema Conversion Tool (SCT) + AWS Database Migration Service (DMS)

This is the official AWS 2-step solution for heterogeneous database migration (Oracle ‚Üí PostgreSQL, SQL Server ‚Üí Aurora, etc.).
Example Migration Flow (Oracle ‚Üí PostgreSQL):

CopyEdit
1. Use **SCT** to convert schema (tables, indexes, stored procs) ‚Üí PostgreSQL-compatible
2. Deploy the converted schema to target RDS PostgreSQL
3. Use **DMS** to:
   - Do full load (migrate data)
   - Optionally enable CDC (change data capture) for near-zero downtime
4. Cutover when app is ready

**What is AWS DataSync?**
üîß Purpose:
High-speed, automated data transfer service to move files to/from AWS.
‚úÖ Use Cases:
Migrate SMB/NFS shares (e.g., your on-prem file servers)


Move logs, backups, archives to S3 / EFS / FSx


Daily data sync between on-prem and cloud

## Key Features

| Feature                | Description                                                                                  |
|------------------------|----------------------------------------------------------------------------------------------|
| ‚úÖ SMB/NFS support     | Can directly connect to your on-prem Windows/Linux file shares                               |
| üîÑ Incremental Syncs   | Only transfers changed data after the first run                                              |
| üöÄ High performance    | Uses purpose-built agent for 10x faster transfer than scripts                                |
| üîê Secure + scheduled  | Uses TLS, IAM roles, and supports automated scheduling                                       |

Where it Sends Data:
S3 buckets
Amazon FSx (Windows File Server)
Amazon EFS

**üí° Part 2: What is VM Import/Export?**
üîß Purpose:
Convert on-prem VM images (e.g., VMware, Hyper-V) into EC2 instances.
‚úÖ Use Cases:
Lift-and-shift VM-based apps
Preserve full software/config state
Create custom EC2 AMIs from VMs
**üß¨ Supported formats:**
OVA
VMDK
VHD
**üìù Requirements:**
Upload VM image to S3
Create IAM role with import permissions
Use AWS CLI or API to import and convert into EC2 AMI

# AWS DataSync + VM Import/Export

## Use Case:
Migrate SMB shares + VMware VMs to AWS

## DataSync:
- For SMB/NFS file transfer
- Transfers data to S3, FSx, or EFS
- Scheduled, incremental, secure
- Uses on-prem **DataSync Agent**

## VM Import/Export:
- Upload .vmdk/.vhd/.ova to S3
- Converts to EC2 AMI
- Use AWS CLI to import and launch EC2

## Exam Tip:
‚úÖ Use **DataSync** for file server migration  
‚úÖ Use **VM Import/Export** for full VM lift-and-shift

# üß† Amazon SQS vs. Amazon MQ ‚Äì AWS SA Pro Exam Comparison

| Feature                         | Amazon SQS                                                | Amazon MQ                                                  |
|---------------------------------|------------------------------------------------------------|------------------------------------------------------------|
| **Purpose**                     | Fully managed message queue service                        | Managed message broker service                             |
| **Best For**                    | New apps that need scalable, decoupled messaging           | Legacy apps requiring compatibility with existing brokers  |
| **Protocols Supported**         | Proprietary AWS API (send/receive/delete messages)         | Industry-standard protocols: AMQP, MQTT, OpenWire, STOMP   |
| **Queue Types**                 | Standard (at-least-once), FIFO (exactly-once)              | Topics and queues (JMS-like model)                         |
| **Scalability**                 | Virtually unlimited, serverless                            | Scales vertically; not suitable for high TPS (by default)  |
| **Ordering Guarantees**        | FIFO queue for strict ordering                             | Supports ordering via topics or queues                     |
| **Latency**                     | Low latency (millisecond)                                  | Higher than SQS; depends on broker health                  |
| **Management Overhead**        | Minimal (no server to manage)                              | Medium (broker configuration, failover handling)           |
| **Durability**                  | Highly durable (SQS stores messages across AZs)            | Durable based on broker configuration                      |
| **Retry/Dead Letter Support**  | Built-in retry and DLQ support                             | Retry/DLQ managed by broker policy                         |
| **Monitoring**                  | CloudWatch metrics for queue length, age, etc.             | CloudWatch + detailed broker logs                          |
| **Message Retention**          | Up to 14 days                                              | Depends on broker settings                                 |
| **Cost Efficiency**            | Pay-per-request, very low-cost                             | Charged per broker instance and throughput                 |
| **Use Case Examples**          | Decoupled microservices, background jobs, event queues     | Migrating JMS-based apps to cloud, on-prem broker lift-n-shift |
| **Recommended When**           | You‚Äôre building cloud-native apps or want massive scale    | You have existing broker-dependent systems                 |
| **Not Ideal For**              | Apps needing MQTT/JMS/AMQP protocols                       | High-throughput modern cloud-native apps                   |

## üî• Exam Tip:
- Use **Amazon MQ** for **broker migration** or **JMS protocol compatibility**
- Use **Amazon SQS** for **serverless, decoupled, high-scale messaging**

**What is AWS Direct Connect?**

Direct Connect (DX) gives you a private, dedicated network connection between your on-prem data center and your AWS VPC.
Bypasses the internet
Low latency
Secure and reliable
Ideal for legacy workloads needing consistent throughput

üß™ Used when:
Applications require a private and dedicated connection

You need high bandwidth and low-latency for apps like SAP, Oracle, on-prem DBs, etc.

üî∑ Why do I need BGP for Direct Connect?
BGP (Border Gateway Protocol) is the routing protocol used to exchange routes between:
Your on-prem router
AWS's Direct Connect router

Think of BGP as the GPS that lets both ends know:
"Hey, here‚Äôs how you can reach all these networks I own."
üí° BGP MD5 authentication is just a security layer ensuring the routers trust each other.
üîê Without BGP ‚Üí Your Direct Connect can‚Äôt route traffic.

On-Premises Data Center
        |
    [Router] -- BGP
        |
  AWS Direct Connect
        |
   Your VPC (Private IPs)
        |
   EC2 runs legacy app

### ‚ùÑÔ∏è AWS Snowball Edge ‚Äì Performance Optimization

**Top Strategies to Speed Up Transfer:**
- üîÅ **Use multiple concurrent copy sessions** (most impact)
- üì¶ **Batch small files** (< 1 MB) into `.zip`, `.tar`, `.tgz` archives
- üö´ Avoid modifying/renaming files during transfer
- üîó Minimize network hops: source, Snowball, and transfer PC on same switch
- ‚ö° Use high-speed NICs (10/40/100 Gbps), **not USB** (not supported)

**Remember:**
- Clustering = capacity & durability (not copy speed)
- File interface = file-level copy
- S3 Adapter = object-based programmatic upload (not faster for files)

## ‚ùÑÔ∏è AWS Snowball Edge ‚Äì Transfer Performance Key Concepts

| Concept                         | Explanation                                                                 | Exam Hint                                                   |
|---------------------------------|-----------------------------------------------------------------------------|-------------------------------------------------------------|
| **Parallel Copy Sessions**      | Most impactful way to improve performance. Open multiple terminal sessions to write data in parallel. | ‚úÖ Best choice when performance is slower than expected      |
| **Batch Small Files**           | Small files (under 1 MB) create high encryption overhead. Compress into `.tar`, `.zip`, or `.tgz` before copying. | ‚úÖ Do this for millions of log files                         |
| **Use High-Speed Network Ports**| Use 10/40/100 Gbps Ethernet ports (not USB ‚Äî Snowball Edge doesn‚Äôt support USB). | ‚ùå Never select "USB transfer" options                       |
| **Minimize Network Hops**       | Connect device + source + transfer terminal to the same switch. Avoid extra routers or switches. | üîç Improves real throughput, especially in busy networks     |
| **Keep Files Static During Transfer** | Do not rename, modify, or write to files during copy. It slows down transfer speed. | ‚ö†Ô∏è Avoid unnecessary filesystem changes mid-copy             |
| **Clustered Snowball Edge Devices** | Helps with storage capacity and durability, not speed of a single copy job. | ‚ùå Don‚Äôt assume clustering = faster ingestion   

How to NEVER Miss Snowball in Migration Scenarios Again
Here‚Äôs a simple mental checklist for spotting Snowball as the right solution:
üí° Snowball Trigger Rules (use if 1 or more is true):
>10TB data
Slow network connection (e.g., <100 Mbps)
Migration must happen quickly (‚â§ 1 month)
One-time or initial full data load
Files, DBs, or backups need physical transfer

üí° Snowball + DMS Hybrid Pattern (often tested):
Use Snowball for bulk initial data transfer
Use DMS for ongoing replication + near-zero-downtime cutover

‚ÄúBig Data, Slow Pipe? Snowball Rides First. DMS Drives After.‚Äù
(Say this every time you see >10TB + VPN)
When you see:
‚ÄúVMware‚Äù + ‚ÄúvCenter‚Äù + ‚Äúwant AMIs‚Äù or ‚Äúmove to EC2‚Äù

üîí Always default to:
 ‚úÖ AWS Application Migration Service (MGN)
 ‚úÖ Install Replication Agent on VMs

 # IBM MQ vs Amazon MQ vs Amazon SQS

| Feature           | IBM MQ                          | Amazon MQ                                        | Amazon SQS                                    |
|-------------------|----------------------------------|--------------------------------------------------|-----------------------------------------------|
| **Purpose**        | Enterprise message broker        | Managed broker service compatible with IBM MQ    | Lightweight, scalable queue service           |
| **Protocols Supported** | JMS, MQTT, AMQP, STOMP          | Same as IBM MQ (JMS, STOMP, etc.)                | Proprietary only, no MQ compatibility         |
| **Migration Type** | Re-platform to Amazon MQ         | ‚úîÔ∏è 1:1 feature match, lift-and-shift ready         | ‚ùå Feature mismatch                            |
| **Use Case**       | Complex enterprise apps          | Legacy MQ migration to AWS                       | Modern microservices needing decoupled queues |
| **FIFO?**          | Yes                              | Yes                                              | Yes (Standard and FIFO queues available)      |

# AWS Cloud Migration Strategies ‚Äì The 6 Rs

## 1. Rehost (‚ÄúLift and Shift‚Äù)
In a large legacy migration scenario where the organization is looking to quickly implement its migration and scale to meet a business case, the majority of applications are typically **rehosted**.

> üîπ Fastest path to the cloud  
> üîπ No changes to the application  
> üîπ Ideal for large-scale migrations

## 2. Replatform (‚ÄúLift, Tinker and Shift‚Äù)
This entails making **a few cloud optimizations** in order to achieve tangible benefits without changing the **core architecture** of the application.

> üîπ Example: Move database from self-managed to RDS  
> üîπ Retains existing app structure  
> üîπ Reduces operational burden

## 3. Repurchase (‚ÄúDrop and Shop‚Äù)
This is a decision to **move to a different product**, often SaaS-based, and usually means your organization is **changing its licensing model**.

> üîπ Example: Move CRM to Salesforce  
> üîπ Good for eliminating legacy license overhead  
> üîπ May provide modernized feature sets

## 4. Refactor / Re-architect
Driven by a strong business need to **add features, scale, or performance**, which would otherwise be difficult to achieve in the application‚Äôs current environment.

> üîπ Example: Move monolith to microservices  
> üîπ High effort, high reward  
> üîπ Cloud-native transformation

## 5. Retire
Identify IT assets that are **no longer useful or in use**. Retiring them helps streamline operations and boost the business case for cloud adoption.

> üîπ Reduces technical debt  
> üîπ Frees up budget and resources  
> üîπ Cleans up legacy environment

## 6. Retain
You may want to **keep certain applications on-premises** because they are not ready for migration or recently upgraded.

> üîπ Example: Apps under active vendor contracts  
> üîπ Useful for phased migrations  
> üîπ ‚ÄúRevisit later‚Äù strategy

Mnemonic to Remember
‚ÄúIf it‚Äôs RAC, then use EC2 back.‚Äù
 If your app needs Oracle RAC, you must go back to EC2 instead of using RDS.
And for backups:
‚ÄúDLM wins over scripts.‚Äù
 Let AWS Data Lifecycle Manager handle snapshots ‚Äî more reliable, less error-prone, policy-driven.
‚ÄúTraffic spike? Use CloudFront‚Äôs edge to fight.‚Äù
 CloudFront buys you time, speed, and global scale, immediately.
‚ÄúWAF at the edge stops the wedge.‚Äù
 Deploy AWS WAF at CloudFront to block exploits right at the edge ‚Äî before they hit your app.